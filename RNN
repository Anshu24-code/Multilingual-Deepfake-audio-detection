import numpy as np
import pandas as pd
import librosa
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from tensorflow.keras.layers import BatchNormalization, Input, Dense, Dropout, Concatenate, LSTM
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import classification_report, confusion_matrix, roc_curve
import seaborn as sns
import matplotlib.pyplot as plt
import os

# Define the audio folder path
audio_folder_path = file path

def extract_features(file_name):
    try:
        audio_path = os.path.join(audio_folder_path, f"{file_name}.mp3")
        audio, sample_rate = librosa.load(audio_path, sr=None)

        # MFCC features
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
        mfccs_scaled = np.mean(mfccs.T, axis=0)

        # Mel spectrogram features
        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate)
        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)
        mel_spectrogram_scaled = np.mean(mel_spectrogram_db.T, axis=0)

        # Pitch frequency
        pitches, magnitudes = librosa.piptrack(y=audio, sr=sample_rate)
        pitch_freq = np.mean([pitches[magnitudes[:, i].argmax(), i] for i in range(magnitudes.shape[1])]) if magnitudes.size > 0 else 0

        # Onset strength
        onset_strength = librosa.onset.onset_strength(y=audio, sr=sample_rate)
        onset_strength_mean = np.mean(onset_strength) if onset_strength.size > 0 else 0

        # Harmonicity
        harmonic = librosa.effects.harmonic(y=audio)
        harmonic_mean = np.mean(harmonic) if harmonic.size > 0 else 0

        # Jitter and shimmer
        fundamental_freqs, _ = librosa.piptrack(y=audio, sr=sample_rate)
        fundamental_freqs = fundamental_freqs[fundamental_freqs > 0]
        jitter = np.std(fundamental_freqs) / np.mean(fundamental_freqs) if len(fundamental_freqs) > 0 else 0

        amplitude = np.abs(audio)
        shimmer = np.std(amplitude) / np.mean(amplitude) if len(amplitude) > 0 else 0

        # Combine features
        combined_features = np.hstack((
            mfccs_scaled,
            mel_spectrogram_scaled,
            [pitch_freq, onset_strength_mean, harmonic_mean, jitter, shimmer]
        ))

        return (combined_features - np.mean(combined_features)) / np.std(combined_features)
    except Exception as e:
        print(f"Error encountered while parsing file: {file_name}, {e}")
        return None

# Load and process data
file_path = labels csv file path
data = pd.read_csv(file_path)

# Encode the categorical data
le_language = LabelEncoder()
le_detection = LabelEncoder()
data['language'] = le_language.fit_transform(data['language'])
data['detection'] = le_detection.fit_transform(data['detection'])

# Extract features
data['features'] = data['Audio'].apply(lambda x: extract_features(x))

# Replace missing features with the mean value of each feature column
features_array = np.array(data['features'].tolist())
means = np.nanmean(features_array, axis=0)
data['features'] = data['features'].apply(lambda x: np.nan_to_num(x, nan=means))

# Save the dataset with features and labels to a CSV file
features_df = pd.DataFrame(data['features'].tolist())
features_df['language'] = data['language']
features_df['detection'] = data['detection']
features_df.to_csv('features_data_rnn.csv', index=False)
print(f"Features with labels saved to features_data_rnn.csv")

# Ensure there are valid features before proceeding
if data.empty:
    print("No valid audio files processed. Check the file paths and formats.")
else:
    # Convert features to numpy array
    X = np.array(data['features'].tolist())
    y = np.array(data['detection'].tolist())
    language = np.array(data['language'].tolist())
    
    # Dimensionality Reduction
    pca = PCA(n_components=0.95)  # Retain 95% of variance
    X_reduced = pca.fit_transform(X)

    # Expand dimensions for LSTM
    X_reduced = np.expand_dims(X_reduced, axis=1)

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test, lang_train, lang_test = train_test_split(X_reduced, y, language, test_size=0.2, random_state=42)

    # Build the LSTM model
    input_audio = Input(shape=(X_train.shape[1], X_train.shape[2]))  # (timesteps, features)
    input_lang = Input(shape=(1,))  

    # Audio feature layers
    x = LSTM(128, return_sequences=True)(input_audio)
    x = Dropout(0.5)(x)
    x = LSTM(64)(x)
    x = Dropout(0.5)(x)
    x = Dense(256, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(0.5)(x)

    # Language feature layers
    y_lang = Dense(128, activation='relu')(input_lang)
    y_lang = Dropout(0.5)(y_lang)

    # Concatenate audio and language features
    combined = Concatenate()([x, y_lang])

    # Final output layer
    z = Dense(256, activation='relu')(combined)
    z = Dropout(0.5)(z)
    output = Dense(2, activation='softmax')(z)  

    model_rnn = Model(inputs=[input_audio, input_lang], outputs=output)
    model_rnn.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(learning_rate=0.001))

    # Early stopping to prevent overfitting
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

    # Train the model
    model_rnn.fit([X_train, lang_train], to_categorical(y_train), epochs=50, batch_size=32, validation_data=([X_test, lang_test], to_categorical(y_test)), callbacks=[early_stopping])

    # Evaluate the model
    train_loss, train_accuracy = model_rnn.evaluate([X_train, lang_train], to_categorical(y_train), verbose=0)
    print(f"Training accuracy: {train_accuracy * 100:.2f}%")

    test_loss, test_accuracy = model_rnn.evaluate([X_test, lang_test], to_categorical(y_test), verbose=0)
    print(f"Test accuracy: {test_accuracy * 100:.2f}%")

    # Detailed evaluation
    y_pred_proba = model_rnn.predict([X_test, lang_test])
    y_pred_classes = np.argmax(y_pred_proba, axis=1)
    y_true = np.argmax(to_categorical(y_test), axis=1)

    print("Classification Report:\n", classification_report(y_true, y_pred_classes))

    conf_matrix = confusion_matrix(y_true, y_pred_classes)
    plt.figure(figsize=(10,7))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Compute EER
    def compute_eer(y_true, y_scores):
        fpr, tpr, thresholds = roc_curve(y_true, y_scores)
        eer_index = np.nanargmin(np.abs(fpr - (1 - tpr)))
        eer = (fpr[eer_index] + (1 - tpr[eer_index])) / 2
        eer_threshold = thresholds[eer_index]
        return eer, eer_threshold

    # Get prediction probabilities for the positive class
    y_pred_proba_pos = y_pred_proba[:, 1]  # Assuming binary classification and positive class is index 1

# Compute EER
def compute_eer(y_true, y_scores):
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    eer_index = np.nanargmin(np.abs(fpr - (1 - tpr)))
    eer = (fpr[eer_index] + (1 - tpr[eer_index])) / 2
    eer_threshold = thresholds[eer_index]
    return eer, eer_threshold

# Get prediction probabilities for the positive class
y_pred_proba_pos = y_pred_proba[:, 1]  # Assuming binary classification and positive class is index 1

# Compute EER
eer, eer_threshold = compute_eer(y_true, y_pred_proba_pos)
print(f"EER: {eer:.4f}")

# Compute DCF
def compute_dcf(y_true, y_scores, threshold, cost_fp=1, cost_fn=1, p_target=0.5):
    predicted_labels = (y_scores >= threshold).astype(int)
    fp = np.sum((predicted_labels == 1) & (y_true == 0))
    fn = np.sum((predicted_labels == 0) & (y_true == 1))
    p_fa = fp / np.sum(y_true == 0)
    p_md = fn / np.sum(y_true == 1)
    dcf = (cost_fp * p_fa + cost_fn * p_md) / (cost_fp * p_target + cost_fn * (1 - p_target))
    return dcf

# Compute DCF at the EER threshold
dcf = compute_dcf(y_true, y_pred_proba_pos, threshold=eer_threshold)
print(f"DCF at EER threshold: {dcf:.4f}")
