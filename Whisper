import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_curve
import seaborn as sns
import matplotlib.pyplot as plt
import torch
import torchaudio
from transformers import WhisperProcessor, WhisperModel
from torch.utils.data import DataLoader, TensorDataset
from torch import nn
import torch.optim as optim
import os

# Define the audio folder path
audio_folder_path = file path

# Load and process data
file_path = labels csv file path
data = pd.read_csv(file_path)

# Encode the categorical data
le_language = LabelEncoder()
le_detection = LabelEncoder()
data['language'] = le_language.fit_transform(data['language'])
data['detection'] = le_detection.fit_transform(data['detection'])

# Function to load and process audio
def load_audio(file_name):
    audio_path = os.path.join(audio_folder_path, f"{file_name}.mp3")
    waveform, sample_rate = torchaudio.load(audio_path)
    return waveform.squeeze().numpy()

# Load Whisper processor and model
processor = WhisperProcessor.from_pretrained("openai/whisper-tiny")
whisper_model = WhisperModel.from_pretrained("openai/whisper-tiny")

# Extract features using Whisper
def extract_features(audio):
    inputs = processor(audio, sampling_rate=16000, return_tensors="pt").input_features
    with torch.no_grad():
        outputs = whisper_model.encoder(inputs)
    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()

# Extract features for all audio files
data['features'] = data['Audio'].apply(lambda x: extract_features(load_audio(x)))

# Prepare features and labels
X = np.array(data['features'].tolist())
y = np.array(data['detection'].tolist())
language = np.array(data['language'].tolist())

# Split the data
X_train, X_test, y_train, y_test, lang_train, lang_test = train_test_split(X, y, language, test_size=0.2, random_state=42)

# Define a simple classification model
class SimpleClassifier(nn.Module):
    def __init__(self, input_dim):
        super(SimpleClassifier, self).__init__()
        self.fc1 = nn.Linear(input_dim, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 2)  # 2 for binary classification
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

# Prepare data loaders
train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))
test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Initialize the model, loss function, and optimizer
model = SimpleClassifier(X_train.shape[1])
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 50
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for batch_features, batch_labels in train_loader:
        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)
        optimizer.zero_grad()
        outputs = model(batch_features)
        loss = criterion(outputs, batch_labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * batch_features.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')

# Final evaluation for total training and testing accuracy
def evaluate_model(loader):
    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []
    with torch.no_grad():
        for batch_features, batch_labels in loader:
            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)
            outputs = model(batch_features)
            _, predicted = torch.max(outputs.data, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(batch_labels.cpu().numpy())
            all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())
    return np.array(all_labels), np.array(all_preds), np.array(all_probs)

train_labels, train_preds, train_probs = evaluate_model(train_loader)
test_labels, test_preds, test_probs = evaluate_model(test_loader)

train_accuracy = np.mean(train_preds == train_labels) * 100
test_accuracy = np.mean(test_preds == test_labels) * 100

print(f'Total Train Accuracy: {train_accuracy:.2f}%')
print(f'Total Test Accuracy: {test_accuracy:.2f}%')

# Detailed classification report for test set
print("Classification Report:\n", classification_report(test_labels, test_preds))

# Plot confusion matrix
conf_matrix = confusion_matrix(test_labels, test_preds)
plt.figure(figsize=(10,7))
sns.heatmap(conf_matrix, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Compute EER
def compute_eer(y_true, y_scores):
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    eer_index = np.nanargmin(np.abs(fpr - (1 - tpr)))
    eer = (fpr[eer_index] + (1 - tpr[eer_index])) / 2
    eer_threshold = thresholds[eer_index]
    return eer, eer_threshold

# Get prediction probabilities for the positive class
y_pred_proba_pos = y_pred_proba[:, 1]  # Assuming binary classification and positive class is index 1

# Compute EER
eer, eer_threshold = compute_eer(y_true, y_pred_proba_pos)
print(f"EER: {eer:.4f}")

# Compute DCF
def compute_dcf(y_true, y_scores, threshold, cost_fp=1, cost_fn=1, p_target=0.5):
    predicted_labels = (y_scores >= threshold).astype(int)
    fp = np.sum((predicted_labels == 1) & (y_true == 0))
    fn = np.sum((predicted_labels == 0) & (y_true == 1))
    p_fa = fp / np.sum(y_true == 0)
    p_md = fn / np.sum(y_true == 1)
    dcf = (cost_fp * p_fa + cost_fn * p_md) / (cost_fp * p_target + cost_fn * (1 - p_target))
    return dcf

# Compute DCF at the EER threshold
dcf = compute_dcf(y_true, y_pred_proba_pos, threshold=eer_threshold)
print(f"DCF at EER threshold: {dcf:.4f}")
