Multilingual Deepfake Detection
The rapid advancement of deepfake technology has outpaced the development of detection methods, particularly for non-English languages. Current research predominantly focuses on identifying fake voices in English, creating a significant gap in our ability to detect audio deepfakes across diverse linguistic landscapes. Although current audio deepfake detection techniques achieve high accuracy, they often sacrifice scalability for efficiency. This trade-off underscores the need for new self-supervised learning (SSL) methods that can reduce the excessive preprocessing required by machine learning techniques and the extra transformations used by deep learning approaches. Despite its potential, SSL has not yet been fully explored in the realm of audio deepfake detection, but it presents a promising solution to address these challenges. Furthermore, the limited availability of high-quality audio datasets for many languages hinders the development and training of robust detection algorithms.
 Addressing this gap is essential to developing robust and reliable deepfake detection solutions that can effectively operate in a multilingual environment. To enhance the applicability of deepfake detection methods globally, it is necessary to explore language-specific modifications that can improve the accuracy and effectiveness of detection models across various linguistic contexts.

Dataset: CVoiceFake (small) is a dataset that features a random selection of 10% of samples from the entire collection. This dataset encompasses five common languages (English, Chinese, German, French, and Italian) and utilizes multi-advanced and classical voice cloning techniques (Parallel WaveGAN, Multi-band MelGAN, Style MelGAN, Griffin-Lim, WORLD, and DiffWave) to produce audio samples that bear a high resemblance to authentic audio.
Available on https://zenodo.org/records/11124319

Labels CSV: Create a CSV file with audio file name, language and type of detection 
